{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Irony Using Google Universal Sentence Encoder\n",
    "In this notebook, I will attempt to detect irony using Google's Universal Sentence Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0427 18:26:25.637270  9944 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras.backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.utils import *\n",
    "from keras.regularizers import *\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ironic examples: 320\n",
      "Non ironic examples: 807\n",
      "Full set (for validation): 1127\n"
     ]
    }
   ],
   "source": [
    "goodreads_irony_f = open(\"goodreads_irony_edited.pickle\", mode=\"rb\")\n",
    "goodreads_knowledge_f = open(\"goodreads_knowledge_keep.pickle\", mode=\"rb\")\n",
    "goodreads_metaphor_f = open(\"goodreads_metaphor_keep.pickle\", mode=\"rb\")\n",
    "\n",
    "goodreads_irony = pickle.load(goodreads_irony_f)\n",
    "goodreads_knowledge = pickle.load(goodreads_knowledge_f)\n",
    "goodreads_metaphor = pickle.load(goodreads_metaphor_f)\n",
    "\n",
    "goodreads_irony_f.close()\n",
    "goodreads_knowledge_f.close()\n",
    "goodreads_metaphor_f.close()\n",
    "\n",
    "ironic = goodreads_irony\n",
    "ironic_labels = np.ones(len(ironic))\n",
    "non_ironic = goodreads_knowledge + goodreads_metaphor\n",
    "non_ironic_labels = np.zeros(len(non_ironic))\n",
    "full_set = ironic + non_ironic\n",
    "full_labels = np.concatenate([ironic_labels, non_ironic_labels])\n",
    "\n",
    "ironic_size = len(ironic)\n",
    "non_ironic_size = len(non_ironic)\n",
    "full_set_size = len(full_set)\n",
    "\n",
    "print(\"Ironic examples: \" + str(ironic_size))\n",
    "print(\"Non ironic examples: \" + str(non_ironic_size))\n",
    "print(\"Full set (for validation): \" + str(full_set_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845\n",
      "845\n",
      "282\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "full_set_np = np.asarray(full_set)\n",
    "\n",
    "train_features = np.concatenate([full_set_np[0:240], full_set_np[320:925]])\n",
    "train_labels = np.concatenate([np.ones(240), np.zeros(605)])\n",
    "\n",
    "test_features = np.concatenate([full_set_np[240:320], full_set_np[925:1127]])\n",
    "test_labels = np.concatenate([np.ones(80), np.zeros(202)])\n",
    "\n",
    "print(len(train_features))\n",
    "print(len(train_labels))\n",
    "print(len(test_features))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (train_features.shape[0],1))\n",
    "test_features = np.reshape(test_features, (test_features.shape[0],1))\n",
    "x = np.reshape(full_set_np, (full_set_np.shape[0],1))\n",
    "y = to_categorical(full_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0427 18:26:34.499387  9944 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.64562017e-02,  6.23100176e-02,  3.46776913e-03,\n",
       "         4.70204279e-03,  3.23413201e-02,  9.14165005e-03,\n",
       "        -3.01914979e-02, -3.84491310e-02, -3.57649252e-02,\n",
       "        -4.20018146e-03, -1.91205703e-02,  2.40280163e-02,\n",
       "         5.23959063e-02,  2.04604957e-02,  3.24646309e-02,\n",
       "         8.14204291e-02, -3.86404321e-02,  1.64812542e-02,\n",
       "         1.34157818e-02, -3.47102135e-02,  7.75472447e-02,\n",
       "        -7.51131922e-02,  1.21427458e-02,  4.46278341e-02,\n",
       "         7.48834983e-02, -1.19225457e-02, -2.63228826e-02,\n",
       "         1.70647651e-02,  7.75867552e-02,  4.95012477e-02,\n",
       "         3.56119871e-02,  4.83054519e-02, -1.33931926e-02,\n",
       "        -2.03491952e-02,  1.61516182e-02, -6.49256110e-02,\n",
       "        -3.63756418e-02, -3.20054255e-02,  4.01207134e-02,\n",
       "         5.42915612e-02, -4.16404940e-02, -5.53556010e-02,\n",
       "        -6.92512095e-02,  4.85552102e-03,  1.49620827e-02,\n",
       "         2.48402003e-02,  1.57571007e-02,  4.47167791e-02,\n",
       "        -7.07037523e-02, -7.17832223e-02,  5.00952639e-03,\n",
       "        -2.59589087e-02, -5.78592904e-02,  2.31313370e-02,\n",
       "         7.53127411e-02,  4.22311127e-02, -1.19252764e-02,\n",
       "         5.68130985e-02,  5.32350363e-03, -2.40766387e-02,\n",
       "        -2.71194614e-02, -1.23549681e-02, -6.05905168e-02,\n",
       "        -1.94701217e-02,  5.49283922e-02, -3.27294543e-02,\n",
       "        -9.29304340e-04,  4.98049296e-02,  4.61435951e-02,\n",
       "         6.48857653e-02, -2.48945551e-03, -8.21273476e-02,\n",
       "         5.40077612e-02, -7.62300938e-02, -4.75528352e-02,\n",
       "        -3.54864188e-02,  7.70851523e-02,  3.46920565e-02,\n",
       "         5.68792820e-02,  7.59117305e-02, -7.16259517e-03,\n",
       "        -8.50538984e-02,  2.76591312e-02, -3.63997780e-02,\n",
       "         5.02404310e-02,  8.57603103e-02,  2.21230891e-02,\n",
       "         4.22035232e-02,  3.18021886e-02, -4.18099612e-02,\n",
       "        -9.60001722e-03, -5.96760325e-02, -5.65165654e-02,\n",
       "         4.37962413e-02, -8.60823169e-02,  6.06312118e-02,\n",
       "        -2.10551303e-02, -3.41948196e-02,  1.73334964e-02,\n",
       "         4.63457033e-02, -3.17540020e-02, -7.34451935e-02,\n",
       "        -6.40494302e-02,  1.19439578e-02, -2.39952859e-02,\n",
       "        -6.31210953e-02, -7.31313601e-02,  1.12030320e-02,\n",
       "         2.50914060e-02, -6.42428026e-02,  6.04019500e-03,\n",
       "        -5.66494986e-02,  4.86478992e-02, -2.28352528e-02,\n",
       "         1.16279554e-02, -6.29272163e-02,  3.89324948e-02,\n",
       "         1.15403673e-03, -8.13435316e-02,  1.51245492e-02,\n",
       "         3.85859683e-02, -4.73999940e-02,  5.69426175e-03,\n",
       "        -6.32515401e-02,  6.23311428e-03, -4.65926602e-02,\n",
       "         4.33222912e-02,  1.46401450e-02, -5.87723181e-02,\n",
       "         5.34503646e-02, -1.35761788e-02,  5.27061448e-02,\n",
       "         9.28275287e-03, -1.61010344e-02,  6.96154833e-02,\n",
       "        -5.09125106e-02,  3.11805774e-02,  3.23532932e-02,\n",
       "        -3.61187905e-02,  2.44922079e-02, -4.39777747e-02,\n",
       "        -5.07643446e-02,  3.91095765e-02, -1.77525450e-02,\n",
       "         6.39121160e-02,  1.66598130e-02,  4.55404120e-03,\n",
       "        -1.29464676e-03,  8.22825078e-03,  6.50314018e-02,\n",
       "        -1.32460836e-02,  8.32513273e-02, -3.42942476e-02,\n",
       "         1.78477373e-02, -8.13246295e-02, -3.97540405e-02,\n",
       "        -1.32131353e-02, -5.71311228e-02,  2.02368982e-02,\n",
       "        -4.40498106e-02, -3.79994810e-02, -1.86461564e-02,\n",
       "         4.07331623e-02, -2.77765258e-03,  7.28997067e-02,\n",
       "         8.29713494e-02, -2.67154556e-02,  5.88389076e-02,\n",
       "         5.46146929e-02,  5.18099479e-02, -5.92902899e-02,\n",
       "         5.34798056e-02,  3.86380330e-02, -3.24837528e-02,\n",
       "        -5.70955165e-02,  9.44633968e-03, -6.27198070e-02,\n",
       "        -3.65421772e-02, -2.33383570e-02,  3.50028500e-02,\n",
       "         4.38573956e-02, -4.85609993e-02,  1.84226874e-02,\n",
       "         2.01100893e-02, -1.02894260e-02,  2.86924522e-02,\n",
       "         8.15729052e-02,  1.87505130e-02,  3.88825648e-02,\n",
       "        -3.92058901e-02,  3.25564072e-02,  1.37221543e-02,\n",
       "        -1.87033713e-02,  5.82602574e-04, -1.98195986e-02,\n",
       "         4.49058935e-02,  4.31735925e-02,  5.82612585e-03,\n",
       "        -3.06446441e-02, -3.99568444e-03,  5.59397601e-02,\n",
       "         2.04245821e-02, -5.58269769e-02,  2.12360602e-02,\n",
       "         2.95248684e-02,  1.50440994e-03,  4.53147069e-02,\n",
       "         1.93627905e-02,  7.12841824e-02, -1.87540916e-03,\n",
       "        -2.23918096e-03, -2.77270866e-03, -5.37293255e-02,\n",
       "         9.34291072e-03, -7.37183988e-02,  3.14655490e-02,\n",
       "         1.18605432e-03,  3.71425115e-02,  2.24868804e-02,\n",
       "        -7.69365802e-02, -1.60495006e-02, -4.29585613e-02,\n",
       "        -8.72697029e-03, -6.05771281e-02, -5.13884984e-02,\n",
       "        -2.42714249e-02,  5.57295531e-02, -5.09858094e-02,\n",
       "         6.49150228e-03,  7.72769377e-03, -4.97083813e-02,\n",
       "        -9.90352780e-03, -7.74186179e-02,  3.16280406e-03,\n",
       "        -1.10710145e-03, -6.82533979e-02,  6.45895079e-02,\n",
       "         3.85526009e-02,  7.03889057e-02, -4.73733991e-02,\n",
       "         4.24536597e-03,  7.10388348e-02, -5.26830442e-02,\n",
       "        -1.78547557e-02,  3.46471667e-02,  1.37007553e-02,\n",
       "         7.50325248e-02,  1.58655327e-02,  4.82993014e-02,\n",
       "        -5.28091267e-02, -2.17354707e-02,  3.33840586e-02,\n",
       "        -7.30166063e-02, -2.03380305e-02,  7.53361434e-02,\n",
       "        -5.36606610e-02, -6.91469461e-02,  3.31886373e-02,\n",
       "        -2.43292581e-02, -5.06511070e-02, -4.21646051e-02,\n",
       "        -2.88240500e-02,  1.00347854e-03,  1.23253418e-02,\n",
       "        -7.22472295e-02,  4.75230590e-02, -4.27448638e-02,\n",
       "         2.77078222e-03,  2.95197740e-02,  1.43667813e-02,\n",
       "        -2.87530906e-02, -3.49552594e-02,  5.99354841e-02,\n",
       "        -4.56110947e-02, -4.72495928e-02, -4.57415581e-02,\n",
       "        -3.81943136e-02,  3.85272391e-02, -2.49122139e-02,\n",
       "         9.83435381e-03,  2.03819387e-02,  7.99411088e-02,\n",
       "        -5.37376292e-02,  3.29349190e-02,  1.11745195e-02,\n",
       "         3.79647354e-05,  6.28444999e-02, -5.14556281e-02,\n",
       "        -4.87262122e-02,  1.89580079e-02, -2.24726424e-02,\n",
       "         9.13025532e-03,  7.16648549e-02,  6.61652610e-02,\n",
       "         6.20802492e-02, -4.49803546e-02, -5.14746923e-03,\n",
       "         1.43364314e-02,  1.27019659e-02, -3.06474399e-02,\n",
       "         3.77705805e-02, -1.55364955e-02, -3.02082766e-02,\n",
       "         3.04549672e-02, -4.91915010e-02,  1.76575929e-02,\n",
       "         1.89216360e-02, -4.03109752e-02,  2.50492860e-02,\n",
       "        -2.64116600e-02,  1.25574721e-02,  8.63712747e-03,\n",
       "         7.05617666e-02,  1.46154445e-02,  5.84375151e-02,\n",
       "         5.82893603e-02, -7.16211125e-02, -3.32859781e-04,\n",
       "        -2.22963076e-02, -4.07282589e-03,  4.22376487e-03,\n",
       "         6.92200959e-02, -4.28796858e-02, -1.53849404e-02,\n",
       "        -7.59255886e-02,  2.36168709e-02,  5.64954504e-02,\n",
       "         3.38702649e-02, -1.22339185e-02, -2.81947479e-02,\n",
       "        -4.28066030e-02, -6.60772622e-02, -2.78431810e-02,\n",
       "         5.56712449e-02, -9.96780489e-03,  4.77544554e-02,\n",
       "         4.71426584e-02, -1.35595608e-03,  3.10320947e-02,\n",
       "        -1.72958020e-02, -2.66696904e-02,  3.81153896e-02,\n",
       "        -7.65143484e-02, -1.63193606e-02,  1.14397882e-02,\n",
       "        -3.46850269e-02, -1.23423645e-02,  1.84045881e-02,\n",
       "        -7.33401701e-02,  4.33905683e-02, -4.61264402e-02,\n",
       "         3.75244133e-02, -8.87119398e-03,  1.11249760e-02,\n",
       "         3.31228003e-02,  3.30728553e-02,  2.44284403e-02,\n",
       "         4.37344844e-03,  3.82500067e-02,  7.10265785e-02,\n",
       "        -5.02741430e-03,  3.86836082e-02, -1.07967211e-02,\n",
       "        -3.73508707e-02, -6.13486543e-02,  1.15152001e-02,\n",
       "         4.02764939e-02,  3.94785069e-02, -2.74731457e-04,\n",
       "         3.01068146e-02,  3.60189863e-02, -6.37078518e-03,\n",
       "         3.71119305e-02, -9.18050949e-03,  4.58870530e-02,\n",
       "        -4.10678573e-02, -7.83641934e-02, -3.77737731e-02,\n",
       "        -3.20528112e-02,  1.00177087e-01, -6.36946112e-02,\n",
       "        -4.32477891e-02, -6.60919724e-03,  2.37202886e-02,\n",
       "        -4.28364053e-03,  2.05248017e-02,  2.26792991e-02,\n",
       "        -8.15324765e-03, -3.24418470e-02,  9.79896113e-02,\n",
       "         6.61640838e-02,  2.18343679e-02, -2.48010573e-03,\n",
       "         7.47742057e-02,  3.48645151e-02,  2.07345914e-02,\n",
       "        -8.56059231e-03, -2.55001765e-02,  7.87802041e-02,\n",
       "        -4.56954986e-02, -4.30152975e-02,  7.15419129e-02,\n",
       "         5.46372570e-02, -5.72429299e-02, -2.59913132e-02,\n",
       "         1.57870762e-02, -4.97328527e-02, -3.95702422e-02,\n",
       "         3.25683579e-02,  7.12217614e-02,  5.05477674e-02,\n",
       "        -1.44158793e-03, -1.10715769e-01, -8.65989402e-02,\n",
       "         4.85498458e-02,  2.28010230e-02,  3.71048413e-02,\n",
       "         7.81487266e-04, -6.49653450e-02, -9.39159002e-03,\n",
       "        -4.03358601e-02, -5.23700118e-02,  1.78787205e-02,\n",
       "         7.30829267e-03,  5.06678708e-02,  3.04411184e-02,\n",
       "        -1.93953272e-02, -7.86726326e-02,  4.46686707e-02,\n",
       "        -8.89489129e-02,  1.29168453e-02,  2.96076946e-02,\n",
       "        -1.52417487e-02, -7.71390321e-03,  3.46271843e-02,\n",
       "        -1.63481589e-02,  3.66119482e-02,  2.54166294e-02,\n",
       "         6.07251301e-02,  3.76869924e-03, -2.63640173e-02,\n",
       "        -7.44659454e-03,  1.96817499e-02, -3.00363954e-02,\n",
       "        -4.06539962e-02, -8.62107649e-02, -7.93070905e-03,\n",
       "        -6.30771741e-02, -5.46475165e-02, -6.53310493e-02,\n",
       "        -3.69131193e-02,  2.53329948e-02, -1.91179961e-02,\n",
       "         5.09124361e-02, -1.19362786e-01,  2.94196680e-02,\n",
       "        -3.64400633e-02, -6.05981387e-02,  4.67517599e-02,\n",
       "         1.88597068e-02,  3.68920341e-02, -4.48148362e-02,\n",
       "        -4.20231521e-02, -4.20422181e-02, -1.26056150e-02,\n",
       "        -7.27929035e-03, -5.90543896e-02,  1.02987640e-01,\n",
       "         3.62535263e-03,  3.62087972e-02, -3.40934768e-02,\n",
       "        -1.59581825e-02,  3.89810395e-03, -4.75073606e-02,\n",
       "         3.44004296e-02,  2.53805872e-02,  1.23102618e-02,\n",
       "        -6.09837919e-02,  6.29641414e-02, -1.39104696e-02,\n",
       "         2.28737984e-02, -4.78222407e-02, -2.57978011e-02,\n",
       "         2.02198122e-02,  7.96239525e-02,  2.05394328e-02,\n",
       "         7.02668652e-02, -3.77013162e-02,  5.25800162e-04,\n",
       "         6.69259727e-02,  6.34444132e-02,  4.15574759e-02,\n",
       "         4.33153696e-02,  6.02175258e-02, -4.87883613e-02,\n",
       "         3.29188700e-03,  6.00611866e-02, -5.79778291e-02,\n",
       "        -2.18846127e-02, -1.28513845e-02, -5.64502589e-02,\n",
       "        -3.06796562e-02, -7.93625340e-02, -1.15407482e-02,\n",
       "         3.61782312e-02, -2.68380009e-02, -4.89818715e-02,\n",
       "         7.10874572e-02,  7.17928559e-02,  8.80630240e-02,\n",
       "         1.85423531e-02, -7.11321756e-02]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = hub.Module('./embeddings/GUSE')\n",
    "test_messages = [\"The quick brown fox jumped over the lazy dog\"]\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    message_embeddings = session.run(embed(test_messages))\n",
    "message_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GUSE(param):\n",
    "    return embed(tf.squeeze(tf.cast(param, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0427 18:26:36.872856  9944 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 189,122\n",
      "Trainable params: 189,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(1,), dtype=tf.string)\n",
    "guse = Lambda(GUSE, output_shape=(512,))(input_layer)\n",
    "dense1 = Dense(256, activation=\"relu\", kernel_regularizer=l2(0.005))(guse)\n",
    "dropout1 = Dropout(0.6)(dense1)\n",
    "dense2 = Dense(128, activation=\"relu\", kernel_regularizer=l2(0.005))(dropout1)\n",
    "dropout2 = Dropout(0.6)(dense2)\n",
    "dense3 = Dense(128, activation=\"relu\", kernel_regularizer=l2(0.005))(dropout2)\n",
    "dropout3 = Dropout(0.6)(dense3)\n",
    "dense4 = Dense(64, activation=\"relu\", kernel_regularizer=l2(0.005))(dropout3)\n",
    "dropout4 = Dropout(0.6)(dense4)\n",
    "output = Dense(2, activation=\"softmax\")(dropout4)\n",
    "model = Model(inputs=[input_layer], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1014 samples, validate on 113 samples\n",
      "Epoch 1/30\n",
      "1014/1014 [==============================] - 4s 4ms/step - loss: 3.8677 - acc: 0.6154 - val_loss: 3.2170 - val_acc: 1.0000\n",
      "Epoch 2/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 2.9681 - acc: 0.6815 - val_loss: 2.3396 - val_acc: 1.0000\n",
      "Epoch 3/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 2.2603 - acc: 0.6844 - val_loss: 1.7390 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 1.7282 - acc: 0.6844 - val_loss: 1.2811 - val_acc: 1.0000\n",
      "Epoch 5/30\n",
      "1014/1014 [==============================] - 1s 999us/step - loss: 1.3333 - acc: 0.6854 - val_loss: 0.9524 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 1.0854 - acc: 0.8393 - val_loss: 0.7551 - val_acc: 0.9558\n",
      "Epoch 7/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.8832 - acc: 0.8876 - val_loss: 0.6395 - val_acc: 0.9558\n",
      "Epoch 8/30\n",
      "1014/1014 [==============================] - 1s 994us/step - loss: 0.7589 - acc: 0.9093 - val_loss: 0.4736 - val_acc: 0.9646\n",
      "Epoch 9/30\n",
      "1014/1014 [==============================] - 1s 985us/step - loss: 0.6625 - acc: 0.9073 - val_loss: 0.4365 - val_acc: 0.9558\n",
      "Epoch 10/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.6003 - acc: 0.9250 - val_loss: 0.3601 - val_acc: 0.9558\n",
      "Epoch 11/30\n",
      "1014/1014 [==============================] - 1s 988us/step - loss: 0.5625 - acc: 0.9191 - val_loss: 0.3560 - val_acc: 0.9558\n",
      "Epoch 12/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.5255 - acc: 0.9369 - val_loss: 0.3609 - val_acc: 0.9381\n",
      "Epoch 13/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.4862 - acc: 0.9300 - val_loss: 0.3222 - val_acc: 0.9292\n",
      "Epoch 14/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.4581 - acc: 0.9290 - val_loss: 0.3024 - val_acc: 0.9381\n",
      "Epoch 15/30\n",
      "1014/1014 [==============================] - 1s 987us/step - loss: 0.4569 - acc: 0.9349 - val_loss: 0.2981 - val_acc: 0.9469\n",
      "Epoch 16/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.4457 - acc: 0.9260 - val_loss: 0.2934 - val_acc: 0.9292\n",
      "Epoch 17/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.4165 - acc: 0.9290 - val_loss: 0.2605 - val_acc: 0.9558\n",
      "Epoch 18/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.4140 - acc: 0.9349 - val_loss: 0.3054 - val_acc: 0.9204\n",
      "Epoch 19/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.4005 - acc: 0.9428 - val_loss: 0.2634 - val_acc: 0.9469\n",
      "Epoch 20/30\n",
      "1014/1014 [==============================] - 1s 992us/step - loss: 0.3896 - acc: 0.9438 - val_loss: 0.2425 - val_acc: 0.9469\n",
      "Epoch 21/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3839 - acc: 0.9448 - val_loss: 0.2189 - val_acc: 0.9558\n",
      "Epoch 22/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3977 - acc: 0.9280 - val_loss: 0.2859 - val_acc: 0.9381\n",
      "Epoch 23/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3850 - acc: 0.9310 - val_loss: 0.2883 - val_acc: 0.9115\n",
      "Epoch 24/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3847 - acc: 0.9379 - val_loss: 0.3005 - val_acc: 0.8938\n",
      "Epoch 25/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3696 - acc: 0.9389 - val_loss: 0.2800 - val_acc: 0.9115\n",
      "Epoch 26/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3674 - acc: 0.9458 - val_loss: 0.2322 - val_acc: 0.9558\n",
      "Epoch 27/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3666 - acc: 0.9467 - val_loss: 0.2477 - val_acc: 0.9381\n",
      "Epoch 28/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3460 - acc: 0.9566 - val_loss: 0.2442 - val_acc: 0.9381\n",
      "Epoch 29/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3469 - acc: 0.9487 - val_loss: 0.2749 - val_acc: 0.9204\n",
      "Epoch 30/30\n",
      "1014/1014 [==============================] - 1s 1ms/step - loss: 0.3422 - acc: 0.9507 - val_loss: 0.2772 - val_acc: 0.9292\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "K.set_session(session)\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())\n",
    "history = model.fit(x, y, batch_size=64, epochs=30, validation_split=0.1, shuffle=True)\n",
    "nonce = str(int(uuid.uuid4()))\n",
    "model.save_weights('./models/guse_model' + nonce + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_f = open(\"twitter_irony_all.pickle\", mode=\"rb\")\n",
    "twitter_data = pickle.load(twitter_f)\n",
    "a = np.zeros((156,1))\n",
    "b = np.ones((156,1))\n",
    "twitter_y = np.concatenate((a,b), axis=1)\n",
    "twitter_x = np.asarray(twitter_data)\n",
    "twitter_x = np.reshape(twitter_x, (twitter_x.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 889us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(twitter_x, twitter_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7948717979284433"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
