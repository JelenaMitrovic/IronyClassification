{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ironic examples: 320\n",
      "Non ironic examples: 807\n",
      "Full set (for validation): 1127\n"
     ]
    }
   ],
   "source": [
    "goodreads_irony_f = open(\"goodreads_irony_edited.pickle\", mode=\"rb\")\n",
    "goodreads_knowledge_f = open(\"goodreads_knowledge_keep.pickle\", mode=\"rb\")\n",
    "goodreads_metaphor_f = open(\"goodreads_metaphor_keep.pickle\", mode=\"rb\")\n",
    "\n",
    "goodreads_irony = pickle.load(goodreads_irony_f)\n",
    "goodreads_knowledge = pickle.load(goodreads_knowledge_f)\n",
    "goodreads_metaphor = pickle.load(goodreads_metaphor_f)\n",
    "\n",
    "goodreads_irony_f.close()\n",
    "goodreads_knowledge_f.close()\n",
    "goodreads_metaphor_f.close()\n",
    "\n",
    "ironic = goodreads_irony\n",
    "ironic_labels = np.ones(len(ironic))\n",
    "non_ironic = goodreads_knowledge + goodreads_metaphor\n",
    "non_ironic_labels = np.zeros(len(non_ironic))\n",
    "full_set = ironic + non_ironic\n",
    "full_labels = np.concatenate([ironic_labels, non_ironic_labels])\n",
    "\n",
    "ironic_size = len(ironic)\n",
    "non_ironic_size = len(non_ironic)\n",
    "full_set_size = len(full_set)\n",
    "\n",
    "print(\"Ironic examples: \" + str(ironic_size))\n",
    "print(\"Non ironic examples: \" + str(non_ironic_size))\n",
    "print(\"Full set (for validation): \" + str(full_set_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845\n",
      "845\n",
      "282\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "full_set_np = np.asarray(full_set)\n",
    "\n",
    "train_features = np.concatenate([full_set_np[0:240], full_set_np[320:925]])\n",
    "train_labels = np.concatenate([np.ones(240), np.zeros(605)])\n",
    "\n",
    "test_features = np.concatenate([full_set_np[240:320], full_set_np[925:1127]])\n",
    "test_labels = np.concatenate([np.ones(80), np.zeros(202)])\n",
    "\n",
    "print(len(train_features))\n",
    "print(len(train_labels))\n",
    "print(len(test_features))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0418 19:58:24.383136  6016 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.41665807, -0.26561025,  0.00393612, -0.01199844,  0.00838736,\n",
       "        -0.12759466,  0.06728889, -0.09666663,  0.05915619, -0.11202545,\n",
       "         0.34699073,  0.0915171 , -0.06559876,  0.24825054, -0.15707098,\n",
       "        -0.29335728,  0.29755536,  0.17687456,  0.06018243, -0.49035624,\n",
       "        -0.26726544, -0.08323846, -0.10170481,  0.2833382 ,  0.3111493 ,\n",
       "         0.0923718 , -0.20664847,  0.0575049 ,  0.18080623,  0.02725045,\n",
       "         0.00090702, -0.11329008,  0.06102838, -0.1938533 , -0.2558603 ,\n",
       "        -0.12667309, -0.03718634,  0.07071813,  0.14304037, -0.28412327,\n",
       "         0.18178123, -0.10954207,  0.13003   , -0.15912755, -0.10998374,\n",
       "        -0.0360543 , -0.17689341,  0.25698033,  0.04685439, -0.15045254]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = hub.Module('./embeddings/NNLM50')\n",
    "test_messages = [\"The quick brown fox jumped over the lazy dog\"]\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    message_embeddings = session.run(embed(test_messages))\n",
    "message_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0418 20:04:14.054710  6016 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0418 20:04:14.105601  6016 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (845, 50)\n",
      "x test shape: (282, 50)\n",
      "y train shape: (845,)\n",
      "y test shape: (282,)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    x_train = session.run(embed(train_features))\n",
    "    x_test = session.run(embed(test_features))\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "print(\"x train shape: \" + str(x_train.shape))\n",
    "print(\"x test shape: \" + str(x_test.shape))\n",
    "print(\"y train shape: \" + str(y_train.shape))\n",
    "print(\"y test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8804733727810651"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8900709219858156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
